import os, streamlit as st
from huggingface_hub import login
from langchain_huggingface import HuggingFaceEmbeddings

hf_token = os.getenv("HF_TOKEN")
if hf_token:
    login(hf_token)                                   # í† í° ë¡œê·¸ì¸
# â¬‡ï¸ í‚¤ì›Œë“œ ì¸ì ì œê±°
emb = HuggingFaceEmbeddings(
    model_name="sentence-transformers/paraphrase-MiniLM-L3-v2"
)


import os, json
import streamlit as st
import csv, pandas as pd
from huggingface_hub import login
from serpapi import GoogleSearch
from transformers import pipeline
from langchain_community.llms import HuggingFacePipeline
from langchain.chains import ConversationalRetrievalChain
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings

# â”€â”€ 0) Hugging Face í† í° ë¡œê·¸ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
hf_token = os.getenv("HF_TOKEN")  # Streamlit Secrets ì— ì €ì¥í•œ í‚¤
if hf_token:
    login(hf_token)

# â”€â”€ 1) ì„¤ì • íŒŒì¼ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with open("config.json", encoding="utf-8")     as f:
    menu_cfg = json.load(f)
with open("publishers.json", encoding="utf-8") as f:
    pub_cfg  = json.load(f)

# â”€â”€ 2) CSV â†’ content ë”•ì…”ë„ˆë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
concepts_df = pd.read_csv("concepts.csv")
problems_df = pd.read_csv("problems.csv")
self_df     = pd.read_csv("self_check.csv")

# ğŸ”¸ exam_tips.csv (unit_id, tip) ëŠ” ì‰¼í‘œê°€ ì„ì—¬ ìˆì–´ ìˆ˜ë™ íŒŒì‹±
tips = []
with open("exam_tips.csv", newline="", encoding="utf-8") as f:
    reader = csv.reader(f)
    next(reader, None)        # í—¤ë” ê±´ë„ˆë›°ê¸° (ì—†ìœ¼ë©´ ìë™ ë¬´ì‹œ)
    for row in reader:
        if not row:
            continue
        unit_id  = row[0]
        tip_text = ",".join(row[1:])     # ì‰¼í‘œ ê°¯ìˆ˜ ìƒê´€ì—†ì´ ë’¤ë¥¼ ì „ë¶€ ê²°í•©
        tips.append({"unit_id": unit_id, "tip": tip_text})
tips_df = pd.DataFrame(tips)

content = {}
for uid, grp in concepts_df.groupby("unit_id"):
    content[uid] = {"concept": grp["concept"].iloc[0]}
for uid, grp in problems_df.groupby("unit_id"):
    content.setdefault(uid, {})["problems"] = grp.to_dict(orient="records")
for uid, grp in self_df.groupby("unit_id"):
    content.setdefault(uid, {})["self_check"] = grp.to_dict(orient="records")
for uid, grp in tips_df.groupby("unit_id"):
    content.setdefault(uid, {})["exam_tips"] = grp["tip"].tolist()

# â”€â”€ 3) SerpAPI ê²€ìƒ‰ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
API_KEY = os.getenv("SERPAPI_API_KEY", "demo")  # demo í‚¤ëŠ” ì œí•œë¨

def web_search(query: str):
    params = {"engine": "google", "q": query, "api_key": API_KEY}
    return GoogleSearch(params).get_dict().get("organic_results", [])

# â”€â”€ 4) RAG ì²´ì¸ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
emb = HuggingFaceEmbeddings(
    model_name="sentence-transformers/paraphrase-MiniLM-L3-v2",  # 20 MB ëª¨ë¸
    huggingfacehub_api_token=hf_token
)
rag_store = FAISS.load_local("rag_index", emb, allow_dangerous_deserialization=True)

gen_pipe = pipeline(
    "text-generation",
    model="TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    tokenizer="TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    max_new_tokens=128,
    temperature=0.7,
)
llm_rag = HuggingFacePipeline(pipeline=gen_pipe)
rag_chain = ConversationalRetrievalChain.from_llm(
    llm=llm_rag,
    retriever=rag_store.as_retriever(search_kwargs={"k": 3})
)

# â”€â”€ 5) Streamlit UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ë‚˜ì¸ìŠ¤í„°ë”” ì±—ë´‡", layout="wide")
st.title("ğŸ§‘â€ğŸ“ ë‚˜ì¸ìŠ¤í„°ë”” ì±—ë´‡")
st.write("ë‚˜ì¸ì´ì—ê²Œ â€˜ìŠ¤í„°ë””ìœ„ë“œë¯¸? ìŠ¤ìœ—ë¯¸!â€™ í•´ ë³´ì„¸ìš” ğŸ˜Š")

mode = st.radio("ì›í•˜ì‹œëŠ” ì„œë¹„ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”", ["ë ˆë²¨í…ŒìŠ¤íŠ¸ ë°›ê¸°", "í•™ìŠµ ë° ì§ˆë¬¸í•˜ê¸°"])
if mode == "ë ˆë²¨í…ŒìŠ¤íŠ¸ ë°›ê¸°":
    st.info("ë ˆë²¨í…ŒìŠ¤íŠ¸ ê¸°ëŠ¥ì€ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.")
    st.stop()

# â”€â”€ 6) í•™ìŠµ & ì§ˆë¬¸ ê²½ë¡œ íƒìƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
path = ["í•™ìŠµ ë° ì§ˆë¬¸í•˜ê¸°"]

def step(opts: dict, label: str):
    choice = st.selectbox(label, list(opts.keys()))
    path.append(choice)
    return opts[choice]

opts1 = menu_cfg["í•™ìŠµ ë° ì§ˆë¬¸í•˜ê¸°"]
opts2 = step(opts1, "ëŒ€ìƒ ì„ íƒ")
opts3 = step(opts2, "ì„¸ë¶€ ì„ íƒ")
if isinstance(opts3, dict) and "ë¶„ë¥˜" in opts3:
    cat = st.selectbox("ë¶„ë¥˜ ì„ íƒ", opts3["ë¶„ë¥˜"])
    path.append(cat)
    pubs = pub_cfg[path[-2]][cat]
    pub  = st.selectbox("êµì¬ ì„ íƒ", list(pubs.keys()))
    path.append(pub)
    unit = st.selectbox("ê³¼ ì„ íƒ", pubs[pub])
    path.append(unit)
else:
    unit = path[-1]

# â”€â”€ 7) ì½˜í…ì¸  ë Œë” + í•˜ì´ë¸Œë¦¬ë“œ QA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
uid = unit.replace(" ", "_")
data = content.get(uid, {})

st.header(f"ğŸ”– {unit}")
st.write("---")

if st.button("1ï¸âƒ£ ê°œë… ìì„¸íˆ ì„¤ëª…"):
    st.markdown(data.get("concept", "ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤."))
    st.write("---")
    qtype = st.radio("ì§ˆë¬¸ ë²”ìœ„", ["êµì¬ ë²”ìœ„", "ì›¹ ì‹¬í™”"], horizontal=True)
    q = st.text_input("ì§ˆë¬¸ ì…ë ¥", key="hybrid_q")
    if q:
        if qtype == "êµì¬ ë²”ìœ„":
            res = rag_chain({"question": q, "chat_history": []})
            st.markdown(res["answer"])
        else:
            for r in web_search(q)[:3]:
                st.markdown(f"**{r['title']}**\n{r['snippet']}\n[{r['link']}]")
    st.write("---")

if st.button("2ï¸âƒ£ ë‹¨ì› ë¬¸ì œ í’€ê¸°"):
    for p in data.get("problems", []):
        ans = st.radio(p["question"], eval(p["choices"]), key=p["q_id"])
        if st.button("ì œì¶œ", key=p["q_id"]):
            st.success("âœ” ì •ë‹µ!" if ans == p["answer"] else "âŒ ì˜¤ë‹µ!")
    st.write("---")

if st.button("3ï¸âƒ£ ì‹¤ë ¥ ì²´í¬"):
    for sc in data.get("self_check", []):
        resp = st.text_input(sc["question"], key=sc["question"])
        if st.button("í™•ì¸", key=sc["question"] + "_chk"):
            st.write("ì •ë‹µ:", sc["answer"])
    st.write("---")

if st.button("4ï¸âƒ£ ì‹œí—˜ í¬ì¸íŠ¸"):
    for tip in data.get("exam_tips", []):
        st.write("â€¢", tip)
    st.write("---")

if st.button("ğŸ”— ì¶”ì²œ ê³µìœ í•˜ê¸°"):
    st.success("https://n9study.example.com  ë¥¼ ì¹œêµ¬ì—ê²Œ ê³µìœ í•˜ì„¸ìš”!")